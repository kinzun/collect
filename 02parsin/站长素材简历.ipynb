{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://zjyd.sc.chinaz.net/Files/DownLoad/jianli/201904/jianli10273.rar\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from lxml import etree\n",
        "import random\n",
        "\n",
        "\n",
        "def rq_url(URL):\n",
        "    HEADERS \u003d {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36\"}\n",
        "\n",
        "    page_html \u003d requests.get(url\u003dURL, headers\u003dHEADERS,)\n",
        "    page_html.encoding \u003d \u0027utf-8\u0027\n",
        "\n",
        "    return page_html\n",
        "\n",
        "\n",
        "\n",
        "def full_info_func():\n",
        "    re \u003d rq_url(URL\u003d\"http://sc.chinaz.com/jianli/free.html\")\n",
        "    html \u003d etree.HTML(re.text)\n",
        "    result \u003d html.xpath(\u0027//*[@id\u003d\"container\"]\u0027)[0]\n",
        "    full_url \u003d []\n",
        "    for i in result:\n",
        "        resume_url \u003d i.xpath(\u0027./p/a\u0027)[0].get(\"href\")\n",
        "        resume_info \u003d i.xpath(\u0027./p/a\u0027)[0].text\n",
        "        full \u003d {\"url\":resume_url,\"title\":resume_info}\n",
        "        full_url.append(full)\n",
        "\n",
        "\n",
        "def download(url):\n",
        "    \n",
        "    re \u003d rq_url(url)\n",
        "    html \u003d etree.HTML(re.text)\n",
        "    result \u003d html.xpath(\u0027//*[@id\u003d\"down\"]/div[2]/ul/li/a\u0027)\n",
        "    download_link \u003d random.choice(result).get(\u0027href\u0027)\n",
        "    \n",
        "    \n",
        "    \n",
        "download(\"http://sc.chinaz.com/jianli/190501265061.htm\")\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "jianli10273.rar\n"
          ]
        }
      ],
      "source": "import requests\nimport random\n\nfrom bs4 import BeautifulSoup\nfrom lxml import etree\nfrom tqdm import tqdm\n\n\nHEADERS \u003d {\n    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36\"}\n\n\ndef rq_url(URL):\n\n    page_html \u003d requests.get(url\u003dURL, headers\u003dHEADERS,)\n    page_html.encoding \u003d \u0027utf-8\u0027\n\n    return page_html\n\n\ndef full_info_func():\n    re \u003d rq_url(URL\u003d\"http://sc.chinaz.com/jianli/free.html\")\n    html \u003d etree.HTML(re.text)\n    result \u003d html.xpath(\u0027//*[@id\u003d\"container\"]\u0027)[0]\n    full_url \u003d []\n    for i in result:\n        resume_url \u003d i.xpath(\u0027./p/a\u0027)[0].get(\"href\")\n        resume_info \u003d i.xpath(\u0027./p/a\u0027)[0].text\n        full \u003d {\"url\": resume_url, \"title\": resume_info}\n        full_url.append(full)\n\n\ndef download(url):\n\n    re \u003d rq_url(url)\n    html \u003d etree.HTML(re.text)\n    result \u003d html.xpath(\u0027//*[@id\u003d\"down\"]/div[2]/ul/li/a\u0027)\n    \n    download_link \u003d random.choice(result).get(\u0027href\u0027)\n    title \u003d html.xpath(\u0027//abs/div[7]/div[2]/div[2]/div[1]/div[1]\u0027)\n    print(title)\n    file_name \u003d download_link.split(\u0027/\u0027)[-1]  # 截取整个url最后一段即文件名\n    print(file_name)\n\n    resp \u003d requests.get(download_link, stream\u003dTrue, headers\u003dHEADERS)\n    # stream\u003dTrue的作用是仅让响应头被下载，连接保持打开状态，\n    # print(resp.headers)\n    content_size \u003d int(resp.headers[\u0027Content-Length\u0027])/1024  # 确定整个安装包的大小\n\n    with open(\"test.rar\", \u0027wb\u0027) as fd:\n                # for chunk in r.iter_content(chunk_size\u003d1024):\n                #     fd.write(chunk)\n        for data in tqdm(iterable\u003dresp.iter_content(1024), total\u003dcontent_size, unit\u003d\u0027k\u0027, desc\u003dfile_name):\n            fd.write(data)\n        print(file_name + \"已经下载完毕！\")\n\n\nurl \u003d \"http://sc.chinaz.com/jianli/190501265061.htm\"\n\ndownload(url)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "# "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}